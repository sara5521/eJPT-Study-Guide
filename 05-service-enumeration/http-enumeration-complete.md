---
title: "HTTP Enumeration Complete Guide"
topic: "HTTP Service Analysis"
exam_objective: "Web service enumeration and information gathering"
difficulty: "Medium"
tools:
  - "Metasploit Framework"
  - "msfconsole"
  - "auxiliary modules"
related_labs:
  - "Web Application Testing"
  - "Directory Enumeration"
  - "File Upload Testing"
file_path: "05-service-enumeration/http-enumeration-complete.md"
last_updated: "2024-09-27"
tags:
  - "http"
  - "web-enumeration"
  - "eJPT"
  - "metasploit"
---

# üîß HTTP Enumeration - Complete Web Service Analysis

**Essential web service enumeration skills for eJPT exam - Master web reconnaissance to succeed!**

## üéØ What is HTTP Enumeration?

**HTTP enumeration** is the process of gathering detailed information about web services running on target systems. This technique is **super important for eJPT exam** because it covers 25% of all enumeration tasks and leads to many exploitation opportunities.

### How HTTP Enumeration Works
```bash
# Basic workflow:
# 1. Identify web service ‚Üí use auxiliary/scanner/http/http_version
# 2. Discover directories ‚Üí use auxiliary/scanner/http/dir_scanner
# 3. Find files ‚Üí use auxiliary/scanner/http/files_dir
# 4. Test file upload ‚Üí use auxiliary/scanner/http/http_put
# 5. Check authentication ‚Üí use auxiliary/scanner/http/http_login
```

### Why It's So Important
- **Web Apps Everywhere** - Most systems run web services
- **Attack Surface** - Web apps have many entry points
- **Information Disclosure** - Often reveals sensitive data
- **eJPT Focus** - 25% of exam scenarios involve web enumeration

---

## üìä HTTP Enumeration Components

### Main Techniques You Must Know
| Technique | What It Does | eJPT Importance |
|-----------|--------------|-----------------|
| **Version Detection** | Identifies web server software | üî¥ Critical - 90% |
| **Directory Discovery** | Finds hidden directories | üî¥ Critical - 85% |
| **File Enumeration** | Locates sensitive files | üî¥ Critical - 80% |
| **Authentication Testing** | Tests login mechanisms | üü° Medium - 60% |
| **File Upload Testing** | Checks upload capabilities | üü° Medium - 50% |

### Module Categories Explained
- **üéØ Version Scanners:** Identify web server type and version (http_version)
- **üìÅ Directory Scanners:** Find hidden paths and directories (dir_scanner)
- **üìÑ File Scanners:** Discover configuration and backup files (files_dir)
- **üîê Authentication:** Test login forms and basic auth (http_login)
- **üì§ Upload Testing:** Check file upload functionality (http_put)

---

## üì¶ Installation and Setup

### System Requirements

#### Prerequisites Needed:
- **Metasploit Framework** installed and working
- **Database connection** configured (for speed)
- **Target accessibility** via HTTP/HTTPS
- **Basic networking** knowledge

### Quick Verification

#### Check Metasploit HTTP Modules
```bash
# Start Metasploit
msfconsole -q

# Verify database connection
msf6 > db_status
# Expected output: [*] Connected to msf. Connection type: postgresql

# Check HTTP modules available
msf6 > search auxiliary/scanner/http

# Should show 50+ HTTP scanning modules
```

#### Test Target Connectivity
```bash
# Basic connectivity test
ping -c 3 target_ip

# HTTP service check
curl -I http://target_ip
# or
telnet target_ip 80
```

---

## üîß Basic Commands and Interface

### Starting HTTP Enumeration

```bash
# Quick start for web enumeration
msfconsole -q

# Set global target (saves time)
setg RHOSTS target_ip
```

### Essential HTTP Modules You Must Know

#### üîç Service Identification Modules
| Module | What It Does | Example Usage |
|--------|--------------|---------------|
| `http_version` | Detects web server version | `use auxiliary/scanner/http/http_version` |
| `http_header` | Analyzes HTTP headers | `use auxiliary/scanner/http/http_header` |
| `robots_txt` | Checks robots.txt file | `use auxiliary/scanner/http/robots_txt` |

#### üìÅ Directory and File Discovery
| Module | What It Does | Example Usage |
|--------|--------------|---------------|
| `dir_scanner` | Brute force directories | `use auxiliary/scanner/http/dir_scanner` |
| `brute_dirs` | Alternative directory scanner | `use auxiliary/scanner/http/brute_dirs` |
| `files_dir` | Finds common files | `use auxiliary/scanner/http/files_dir` |
| `dir_listing` | Checks directory listings | `use auxiliary/scanner/http/dir_listing` |

#### ‚öôÔ∏è Configuration Commands
| Command | What It Does | Example |
|---------|--------------|---------|
| `set RHOSTS` | Set target IP/range | `set RHOSTS 192.168.1.100` |
| `set RPORT` | Set target port | `set RPORT 8080` |
| `set SSL` | Enable HTTPS | `set SSL true` |
| `set TARGETURI` | Set specific path | `set TARGETURI /admin` |
| `set VERBOSE` | Control output detail | `set VERBOSE false` |

#### üöÄ Execution Commands
| Command | What It Does | Example |
|---------|--------------|---------|
| `run` | Execute module | `run` |
| `show options` | Display settings | `show options` |
| `info` | Show module details | `info` |
| `back` | Exit current module | `back` |

---

## üß™ Real Lab Example: Complete Apache Web Server Enumeration

### Step 1: Target Discovery

```bash
# Check if target is alive
ping -c 4 victim-1

# Expected output:
PING victim-1 (192.74.12.3) 56(84) bytes of data.
64 bytes from victim-1 (192.74.12.3): icmp_seq=1 ttl=64 time=0.100 ms
# ‚úÖ TTL=64 means Linux system
# ‚úÖ Fast response means accessible
```

### Step 2: Basic HTTP Service Check

```bash
# Manual HTTP check
curl -I http://victim-1

# Expected response:
HTTP/1.1 200 OK
Date: Wed, 27 Sep 2024 10:30:00 GMT
Server: Apache/2.4.18 (Ubuntu)
Content-Type: text/html

# üéØ Key Info Found:
# - HTTP service responding
# - Apache 2.4.18 web server
# - Ubuntu operating system
```

### Step 3: Start Metasploit Enumeration

```bash
# Launch Metasploit
msfconsole -q

# Set global target to save time
msf6 > setg RHOSTS victim-1
RHOSTS => victim-1

# Verify database connection
msf6 > db_status
[*] Connected to msf. Connection type: postgresql
# ‚úÖ Database working properly
```

### Step 4: Web Server Version Detection

```bash
# Use HTTP version scanner
msf6 > use auxiliary/scanner/http/http_version
msf6 auxiliary(scanner/http/http_version) > show options

Module options (auxiliary/scanner/http/http_version):
   Name     Current Setting  Required  Description
   ----     ---------------  --------  -----------
   Proxies                   no        A proxy chain
   RHOSTS   victim-1         yes       The target host(s)
   RPORT    80              yes       The target port
   SSL      false           no        Negotiate SSL/TLS
   THREADS  1               yes       The number of concurrent threads
   VHOST                    no        HTTP server virtual host

msf6 auxiliary(scanner/http/http_version) > run

[*] 192.74.12.3:80 Apache/2.4.18 (Ubuntu)
[*] Scanned 1 of 1 hosts (100% complete)

# ‚úÖ Web server confirmed: Apache/2.4.18 on Ubuntu
```

### Step 5: HTTP Header Analysis

```bash
# Analyze HTTP headers for more information
msf6 > use auxiliary/scanner/http/http_header
msf6 auxiliary(scanner/http/http_header) > set TARGETURI /
msf6 auxiliary(scanner/http/http_header) > run

[+] 192.74.12.3:80 : CONTENT-TYPE: text/html
[+] 192.74.12.3:80 : LAST-MODIFIED: Wed, 27 Feb 2019 04:21:01 GMT
[+] 192.74.12.3:80 : SERVER: Apache/2.4.18 (Ubuntu)
[+] 192.74.12.3:80 : ETAG: "2aa6-5834e5d732040"
[+] 192.74.12.3:80 : ACCEPT-RANGES: bytes
[+] 192.74.12.3:80 : CONTENT-LENGTH: 10918

# üéØ Useful Information:
# - Last modified date shows when content was updated
# - Content length indicates file sizes
# - ETag reveals server configuration details
```

### Step 6: Robots.txt Discovery

```bash
# Check for robots.txt file
msf6 > use auxiliary/scanner/http/robots_txt
msf6 auxiliary(scanner/http/robots_txt) > run

[+] [192.74.12.3] /robots.txt found
[+] Contents of Robots.txt:
# robots.txt for attackdefense
User-agent: test
# Directories
Allow: /webmail
User-agent: *
# Directories  
Disallow: /data
Disallow: /secure

# üèÜ JACKPOT! Found hidden directories:
# - /webmail (allowed for test user-agent)
# - /data (disallowed - potentially sensitive)
# - /secure (disallowed - likely admin area)
```

### Step 7: Directory Brute Force Attack

```bash
# Use directory scanner with discovered hints
msf6 > use auxiliary/scanner/http/brute_dirs
msf6 auxiliary(scanner/http/brute_dirs) > set VERBOSE false
msf6 auxiliary(scanner/http/brute_dirs) > run

[+] Using code '404' as not found.
[+] Found http://victim-1:80/doc/ 200
[+] Found http://victim-1:80/pro/ 200
[+] Found http://victim-1:80/data/ 200 (discovered from robots.txt)
[+] Found http://victim-1:80/secure/ 200 (discovered from robots.txt)

# More comprehensive directory scan
msf6 > use auxiliary/scanner/http/dir_scanner
msf6 auxiliary(scanner/http/dir_scanner) > set DICTIONARY /usr/share/metasploit-framework/data/wordlists/directory.txt
msf6 auxiliary(scanner/http/dir_scanner) > run

[+] Found http://victim-1:80/cgi-bin/ 403 (Forbidden)
[+] Found http://victim-1:80/icons/ 403 (Forbidden)
[+] Found http://victim-1:80/webmail/ 200
[+] Found http://victim-1:80/admin/ 200

# ‚úÖ Multiple directories discovered successfully
```

### Step 8: File Discovery and Testing

```bash
# Search for common files
msf6 > use auxiliary/scanner/http/files_dir
msf6 auxiliary(scanner/http/files_dir) > set VERBOSE false
msf6 auxiliary(scanner/http/files_dir) > run

[+] Found http://victim-1:80/index.html 200
[+] Found http://victim-1:80/test.php 200
[+] Found http://victim-1:80/config.php 200
[+] Found http://victim-1:80/backup.sql 200

# Test file upload capability
msf6 > use auxiliary/scanner/http/http_put
msf6 auxiliary(scanner/http/http_put) > set PATH /data
msf6 auxiliary(scanner/http/http_put) > set FILENAME test.txt
msf6 auxiliary(scanner/http/http_put) > set FILEDATA "Welcome To AttackDefense"
msf6 auxiliary(scanner/http/http_put) > run

[+] File uploaded: http://192.74.12.3:80/data/test.txt

# Verify upload worked
msf6 > exit
wget http://victim-1:80/data/test.txt
cat test.txt
# Output: Welcome To AttackDefense

# üéâ SUCCESS! File upload vulnerability confirmed
```

### Step 9: Authentication Testing

```bash
# Test protected directory authentication
msfconsole -q
msf6 > use auxiliary/scanner/http/http_header
msf6 auxiliary(scanner/http/http_header) > set RHOSTS victim-1
msf6 auxiliary(scanner/http/http_header) > set TARGETURI /secure
msf6 auxiliary(scanner/http/http_header) > run

[+] 192.74.12.3:80 : WWW-AUTHENTICATE: Basic realm="Restricted Content"

# Try to find valid credentials
msf6 > use auxiliary/scanner/http/http_login
msf6 auxiliary(scanner/http/http_login) > set RHOSTS victim-1
msf6 auxiliary(scanner/http/http_login) > set AUTH_URI /secure/
msf6 auxiliary(scanner/http/http_login) > set VERBOSE false
msf6 auxiliary(scanner/http/http_login) > run

[+] Attempting to login to http://victim-1:80/secure/ (192.74.12.3)
[+] 192.74.12.3:80 - Success: 'bob:123321'

# üèÜ CREDENTIALS FOUND!
# Username: bob
# Password: 123321
```

### Step 10: Complete Mission Summary

```bash
# Summary of discoveries:
# ‚úÖ Web Server: Apache/2.4.18 (Ubuntu)
# ‚úÖ Hidden Directories: /data, /secure, /webmail, /admin
# ‚úÖ File Upload: Possible in /data directory
# ‚úÖ Authentication: Basic auth with weak credentials (bob:123321)
# ‚úÖ Sensitive Files: config.php, backup.sql discovered

# üéØ ENUMERATION COMPLETE!
# Ready for exploitation phase
```

---

## üéØ eJPT Exam Focus (Critical for Success!)

### Exam Statistics You Must Know

| Skill Area | Exam Weight | Time to Spend | Must Master |
|------------|-------------|---------------|-------------|
| **Service Identification** | üî¥ 25% | 5 minutes | http_version, http_header |
| **Directory Discovery** | üî¥ 30% | 10 minutes | robots_txt, dir_scanner |
| **File Enumeration** | üî¥ 25% | 8 minutes | files_dir, sensitive files |
| **Authentication Testing** | üü° 15% | 7 minutes | http_login, basic auth |
| **Upload Testing** | üü° 5% | 5 minutes | http_put method |

### Commands You MUST Memorize

```bash
# 1. BASIC WEB ENUMERATION (Know by heart!)
use auxiliary/scanner/http/http_version         # Always start here
use auxiliary/scanner/http/robots_txt           # Quick directory hints
use auxiliary/scanner/http/dir_scanner          # Find hidden paths

# 2. FILE AND DIRECTORY DISCOVERY (Essential!)
use auxiliary/scanner/http/files_dir            # Common file detection
use auxiliary/scanner/http/brute_dirs          # Directory brute force
set DICTIONARY /usr/share/metasploit-framework/data/wordlists/directory.txt

# 3. AUTHENTICATION AND UPLOAD (Important!)
use auxiliary/scanner/http/http_login          # Credential testing
use auxiliary/scanner/http/http_put            # File upload testing
```

### Common eJPT Scenarios

#### **Scenario 1: Web Server Information Gathering** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
```
What you get: Target system with web service running
What you must do: Identify web server software and version
Time limit: 10 minutes maximum
Success criteria:
‚úÖ Use http_version module correctly
‚úÖ Identify server software (Apache, Nginx, IIS)
‚úÖ Determine version number
‚úÖ Note operating system details
```

#### **Scenario 2: Hidden Content Discovery** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
```
What you get: Web application with hidden directories
What you must do: Find administrative interfaces and sensitive files
Time limit: 15 minutes maximum
Success criteria:
‚úÖ Check robots.txt for directory hints
‚úÖ Use dir_scanner to find hidden paths
‚úÖ Locate admin panels (/admin, /manager)
‚úÖ Find configuration files (config.php, web.config)
```

#### **Scenario 3: File Upload Vulnerability** ‚≠ê‚≠ê‚≠ê‚≠ê
```
What you get: Web server with upload functionality
What you must do: Test file upload capabilities
Time limit: 12 minutes maximum
Success criteria:
‚úÖ Use http_put module
‚úÖ Successfully upload test file
‚úÖ Verify file accessibility
‚úÖ Document upload directory location
```

#### **Scenario 4: Authentication Bypass** ‚≠ê‚≠ê‚≠ê
```
What you get: Protected web directory with basic authentication
What you must do: Find valid credentials
Time limit: 10 minutes maximum
Success criteria:
‚úÖ Identify authentication mechanism
‚úÖ Use http_login module
‚úÖ Test common credentials
‚úÖ Gain access to protected content
```

### Time Management for eJPT

**‚è∞ Optimal Time Distribution for Web Enumeration:**
- **üîç Service Detection:** 5 minutes (15%)
- **üìÅ Directory Discovery:** 10 minutes (30%)
- **üìÑ File Enumeration:** 8 minutes (25%)
- **üîê Authentication Testing:** 7 minutes (20%)
- **üìù Documentation:** 3 minutes (10%)

### Success Tips for eJPT

**üî• Before Starting Web Enumeration:**
- Always verify HTTP service is actually running
- Check both HTTP (80) and HTTPS (443) if available
- Set global RHOSTS to save time during exam
- Have wordlist paths memorized

**üî• During Web Enumeration:**
- Start with robots.txt - it often gives you directory hints
- Use VERBOSE false to reduce output clutter
- Take screenshots of all discovered directories
- Test file upload immediately when found

**üî• Common Mistakes to Avoid:**
- ‚ùå Skipping robots.txt check (misses easy wins)
- ‚ùå Using verbose output (wastes time reading)
- ‚ùå Not testing both HTTP and HTTPS
- ‚ùå Forgetting to document discovered URLs
- ‚ùå Not verifying file uploads actually work

---

## ‚ö†Ô∏è Common Problems and Solutions

### Problem 1: Connection Timeouts During Scanning

**üö® What's wrong:** HTTP modules hang or timeout when scanning target

**üîç Why this happens:**
- Target web server is slow or overloaded
- Network connectivity issues
- Firewall blocking requests
- SSL/TLS configuration problems

**‚úÖ How to fix:**
```bash
# Test basic connectivity first
ping victim-1
curl -I http://victim-1

# Adjust timeout settings
set HttpClientTimeout 30
set HttpReadTimeout 30

# For HTTPS targets
set SSL true
set HttpClientVerifySSL false
```

### Problem 2: Module Returns No Results

**üö® What's wrong:** Directory or file scanners find nothing

**üîç Why this happens:**
- Web server returns custom error pages
- Default wordlists don't match target
- Wrong port or protocol specified
- Rate limiting blocking requests

**‚úÖ How to fix:**
```bash
# Verify HTTP service manually
telnet victim-1 80
GET / HTTP/1.1
Host: victim-1

# Try different wordlists
set DICTIONARY /usr/share/dirb/wordlists/common.txt
set DICTIONARY /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt

# Check different ports
set RPORT 8080
set RPORT 443
set SSL true
```

### Problem 3: File Upload Testing Fails

**üö® What's wrong:** http_put module reports errors or doesn't work

**üîç Why this happens:**
- HTTP PUT method disabled on server
- Insufficient permissions for target directory
- File already exists
- Web server blocks certain file types

**‚úÖ How to fix:**
```bash
# Test manual HTTP PUT first
curl -X PUT -d "test content" http://victim-1/data/test.txt

# Try different directories
set PATH /uploads
set PATH /files
set PATH /temp

# Try different file extensions
set FILENAME test.html
set FILENAME test.txt
set FILENAME test.php
```

### Problem 4: Authentication Testing Issues

**üö® What's wrong:** http_login module doesn't find credentials

**üîç Why this happens:**
- Wrong authentication URI specified
- Target uses form-based instead of basic auth
- Account lockout after failed attempts
- Custom authentication mechanism

**‚úÖ How to fix:**
```bash
# Verify authentication type manually
curl -I http://victim-1/secure/

# Check for different auth paths
set AUTH_URI /admin/
set AUTH_URI /login/
set AUTH_URI /manager/

# Use smaller wordlists to avoid lockout
set USER_FILE /usr/share/metasploit-framework/data/wordlists/common_users.txt
set PASS_FILE /usr/share/metasploit-framework/data/wordlists/common_passwords.txt
set STOP_ON_SUCCESS true
```

---

## üîó Integration with Other Tools

### Main Web Testing Workflow

```bash
# Step 1: Port Discovery (External tools)
nmap -sS -sV -p80,443,8080,8443 target_ip    # Find web ports
nmap --script http-enum target_ip             # Basic HTTP enumeration

# Step 2: Import into Metasploit
msfconsole -q
setg RHOSTS target_ip

# Step 3: Systematic HTTP Enumeration
use auxiliary/scanner/http/http_version       # Service identification
use auxiliary/scanner/http/robots_txt         # Directory hints
use auxiliary/scanner/http/dir_scanner        # Directory discovery
use auxiliary/scanner/http/files_dir          # File enumeration

# Step 4: Advanced Testing
use auxiliary/scanner/http/http_put           # Upload testing
use auxiliary/scanner/http/http_login         # Authentication
```

### Tool Chain Integration

```bash
# Nmap ‚Üí Metasploit ‚Üí Manual Testing workflow

# 1. Nmap discovers web services
nmap -sV -p- target_ip | grep "http"

# 2. Metasploit enumerates web content
msfconsole -q -x "
setg RHOSTS target_ip;
use auxiliary/scanner/http/http_version; run;
use auxiliary/scanner/http/dir_scanner; run;
exit"

# 3. Manual verification with curl/browser
curl http://target_ip/discovered_directory/
firefox http://target_ip/admin/
```

### Database Integration Example

```bash
# Store enumeration results in database
msfconsole -q
setg RHOSTS target_ip

# Run multiple HTTP scans
use auxiliary/scanner/http/http_version; run
use auxiliary/scanner/http/dir_scanner; run
use auxiliary/scanner/http/files_dir; run

# Query results from database
services -c port,name,info -S http
notes -t web.directory
notes -t web.file
```

---

## üìù Documentation and Reporting

### Evidence You Must Collect

**üî• Screenshots Required:**
- [ ] Web server version identification results
- [ ] robots.txt content (if found)
- [ ] Directory enumeration output
- [ ] Successful file upload proof
- [ ] Authentication testing results
- [ ] Discovered administrative interfaces

**üî• Command Logs to Save:**
```bash
# Enable detailed logging
msfconsole -q
msf6 > spool /tmp/http_enum_log.txt

# All HTTP enumeration commands will be logged
# Include timestamps and target information
```

### Professional Report Format

```markdown
# HTTP Enumeration Assessment Report

## Executive Summary
Comprehensive HTTP service enumeration performed against target web server. Multiple security weaknesses identified including information disclosure, weak authentication, and file upload vulnerabilities.

## Target Information
- **Target System:** victim-1 (192.74.12.3)
- **Web Server:** Apache/2.4.18 (Ubuntu)
- **Ports Tested:** 80/HTTP, 443/HTTPS
- **Assessment Date:** September 27, 2024
- **Tools Used:** Metasploit Framework v6.x

## Technical Findings

### 1. Web Server Information Disclosure
**Risk Level:** Medium
**Description:** Web server reveals detailed version information
**Evidence:**
```bash
use auxiliary/scanner/http/http_version
set RHOSTS victim-1
run
# Result: Apache/2.4.18 (Ubuntu) identified
```

### 2. Directory Structure Disclosure
**Risk Level:** High
**Description:** robots.txt file reveals sensitive directory structure
**Evidence:**
- /data directory containing uploadable content
- /secure directory with basic authentication
- /admin administrative interface discovered

### 3. File Upload Vulnerability
**Risk Level:** Critical
**Description:** Unrestricted file upload in /data directory
**Proof of Concept:**
```bash
use auxiliary/scanner/http/http_put
set PATH /data
set FILENAME test.txt
set FILEDATA "Penetration test evidence"
run
# Result: File successfully uploaded and accessible
```

### 4. Weak Authentication
**Risk Level:** High
**Description:** Basic authentication using weak credentials
**Compromised Credentials:**
- Username: bob
- Password: 123321
- Access Level: /secure directory access

## Risk Assessment
- **Immediate Risk:** Unauthorized file upload and system access
- **Data Exposure:** Sensitive configuration files accessible
- **Attack Vectors:** Multiple entry points for further exploitation
- **Business Impact:** Potential data breach and system compromise

## Recommendations

### Critical Actions (0-24 hours)
1. **Disable HTTP PUT method** - Prevent file upload attacks
2. **Remove robots.txt** - Eliminate directory disclosure
3. **Change weak passwords** - Implement strong authentication

### Important Actions (1-7 days)
1. **Implement access controls** - Restrict administrative interfaces
2. **Remove version banners** - Prevent information disclosure
3. **Enable request monitoring** - Detect enumeration attempts

### Long-term Improvements (1-30 days)
1. **Web application firewall** - Implement comprehensive protection
2. **Regular security testing** - Scheduled vulnerability assessments
3. **Security awareness training** - Educate development teams

## Supporting Evidence
- Web server version screenshots
- Directory enumeration results
- File upload demonstration
- Authentication bypass proof
- Complete command execution log
```

---

## üìö Learning Resources and Practice

### Official Documentation
| Resource | Link | Purpose |
|----------|------|---------|
| **Apache HTTP Server** | https://httpd.apache.org/docs/ | Server configuration reference |
| **Metasploit HTTP Modules** | https://docs.rapid7.com/metasploit/ | Module documentation |
| **OWASP Testing Guide** | https://owasp.org/www-project-web-security-testing-guide/ | Web testing methodology |

### Practice Environments

#### **Beginner Level:**
- **DVWA:** Damn Vulnerable Web Application
- **Metasploitable 2:** Vulnerable web services included
- **WebGoat:** OWASP web application security lessons
- **bWAPP:** Buggy Web Application for learning

#### **Intermediate Level:**
- **Mutillidae:** Deliberately vulnerable web application
- **VulnHub Web Challenges:** Specialized web application VMs
- **PentesterLab:** Professional web application exercises
- **TryHackMe Web Rooms:** Guided web enumeration challenges

#### **Advanced Level:**
- **HackTheBox Web Challenges:** Real-world web application scenarios
- **PortSwigger Web Security Academy:** Advanced web security training
- **Custom Lab Environments:** Build your own vulnerable web apps
- **Bug Bounty Platforms:** Real-world web application testing

### eJPT Preparation Schedule

#### **Week 1-2: Foundation Building**
- [ ] Master basic HTTP concepts and protocol understanding
- [ ] Learn Metasploit HTTP module navigation and usage
- [ ] Practice service identification and version detection
- [ ] Understand common web server software differences

#### **Week 3-4: Core Enumeration Skills**
- [ ] Practice directory enumeration daily with different wordlists
- [ ] Master robots.txt analysis and directory hint extraction
- [ ] Learn file discovery techniques and common file locations
- [ ] Develop systematic enumeration methodology

#### **Week 5-6: Advanced Techniques**
- [ ] Practice file upload testing and verification
- [ ] Learn authentication mechanism identification and testing
- [ ] Master integration with external tools (Nmap, curl, browsers)
- [ ] Develop time-efficient enumeration workflows

#### **Week 7-8: Exam Preparation**
- [ ] Take timed practice scenarios
- [ ] Review all critical HTTP modules and commands
- [ ] Practice documentation and reporting skills
- [ ] Final verification of tool setup and functionality

### Quick Reference Commands

```bash
# ESSENTIAL HTTP ENUMERATION SEQUENCE
msfconsole -q                                   # Start framework
setg RHOSTS target_ip                          # Set global target

# SERVICE IDENTIFICATION
use auxiliary/scanner/http/http_version         # Web server detection
use auxiliary/scanner/http/http_header          # Header analysis

# CONTENT DISCOVERY
use auxiliary/scanner/http/robots_txt           # Directory hints
use auxiliary/scanner/http/dir_scanner          # Directory enumeration
use auxiliary/scanner/http/files_dir            # File discovery

# SECURITY TESTING
use auxiliary/scanner/http/http_put             # Upload testing
use auxiliary/scanner/http/http_login           # Authentication testing

# COMMON CONFIGURATIONS
set VERBOSE false                               # Reduce output noise
set SSL true                                    # Enable HTTPS
set RPORT 8080                                  # Alternative port
set DICTIONARY /path/to/wordlist.txt            # Custom wordlist
```

---

## üèÅ Final Exam Preparation

### Self-Assessment Checklist

#### **Technical Skills** (Must Score 90%+)
- [ ] Can identify web server software and version in under 3 minutes
- [ ] Can discover hidden directories using multiple methods
- [ ] Can locate sensitive files and configuration data
- [ ] Can test file upload functionality successfully
- [ ] Can identify and test authentication mechanisms

#### **Practical Application** (Must Score 85%+)
- [ ] Complete comprehensive web enumeration in under 20 minutes
- [ ] Successfully find administrative interfaces
- [ ] Demonstrate file upload vulnerabilities
- [ ] Document all findings with proper evidence
- [ ] Integrate results with further exploitation planning

#### **Exam Readiness** (Must Score 80%+)
- [ ] Can work efficiently under time pressure
- [ ] Knows when to use automated vs manual techniques
- [ ] Can troubleshoot common enumeration issues
- [ ] Maintains professional documentation standards
- [ ] Demonstrates systematic methodology throughout

### Last-Minute Review

**üî• The Night Before Exam:**
1. **Verify Tool Setup:** Test Metasploit HTTP modules work properly
2. **Review Command Sequences:** Practice essential enumeration workflows
3. **Check Wordlist Locations:** Ensure dictionary files are accessible
4. **Test Network Connectivity:** Verify HTTP/HTTPS access works
5. **Prepare Documentation:** Set up logging and screenshot tools

**üî• Day of Exam:**
1. **Start Systematically:** Begin with service identification always
2. **Follow Methodology:** Use consistent enumeration approach
3. **Document Everything:** Screenshot all discoveries immediately
4. **Verify Results:** Manually confirm automated scan findings
5. **Manage Time Wisely:** Don't spend too long on single targets

---

## üéä Conclusion

HTTP enumeration is a fundamental skill for web application penetration testing and absolutely essential for eJPT certification success. This comprehensive guide provides everything needed to master web service enumeration from basic service identification to advanced vulnerability testing.

### Key Takeaways

1. **Start with Service Identification:** Always begin with http_version and http_header modules
2. **Check robots.txt First:** Quick wins often come from directory disclosure files
3. **Systematic Approach:** Follow consistent methodology for reliable results
4. **Document Everything:** Professional reporting demonstrates real-world competency
5. **Practice Integration:** Combine Metasploit with manual verification techniques

### Next Steps After Mastering HTTP Enumeration

- **Web Application Exploitation:** Apply enumeration results to find exploitable vulnerabilities
- **Advanced Web Testing:** Learn complex authentication bypass and injection techniques
- **Automated Tool Integration:** Combine with Burp Suite, OWASP ZAP, and custom scripts
- **Bug Bounty Hunting:** Apply skills to real-world web application assessments
- **Specialized Certifications:** Progress to OSCP, GWEB, or vendor-specific web security certs

### Final Words

Remember that web enumeration is about understanding the attack surface, not causing harm. Use these skills responsibly, always within authorized scope, and contribute positively to improving web application security.

**Master HTTP enumeration, ace the eJPT, and build strong web application testing skills! üî•üéØ**

---

*This guide represents real-world web application testing scenarios and examination requirements. Practice ethically and always obtain proper authorization before testing any systems.*
